{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](house_prices.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T16:35:52.273740Z",
     "start_time": "2021-08-04T16:35:52.268092Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a standard library for data manipulation: https://pandas.pydata.org/docs/user_guide/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T16:33:10.054472Z",
     "start_time": "2021-08-04T16:33:10.034502Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"house_sales_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T16:33:10.121600Z",
     "start_time": "2021-08-04T16:33:10.098780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas' base object is the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T16:33:10.255339Z",
     "start_time": "2021-08-04T16:33:10.169765Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T16:35:57.188998Z",
     "start_time": "2021-08-04T16:35:57.109191Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: trouver et appliquer la méthode des dataframes pandas \n",
    "# permettant de retirer toutes les colonnes contenant des valeurs manquantes (None, Na)\n",
    "df_with_dropped_na = ?? \n",
    "assert(len(df_with_dropped_na.columns) == 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dropped_na.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conserver seulement les colonnes numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_with_dropped_na.dtypes.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "df_numeric = df_with_dropped_na.select_dtypes(numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_numeric.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seaborn est une librairie haut-niveau de visualisation de données, \n",
    "basée sur une librairie plus standard mais plus bas-niveau, matplotlib\n",
    "https://seaborn.pydata.org/examples/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(df_numeric.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "correlations = df_numeric.corr()\n",
    "most_correlated_features = correlations[\"SalePrice\"].sort_values(ascending=False)[:15]\n",
    "most_correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "correlations_most_correlated_features = df_numeric[most_correlated_features.index].corr()\n",
    "sns.heatmap(correlations_most_correlated_features, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=df_numeric.OverallQual, y=df_numeric.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premier modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cible et variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "target = \"SalePrice\"\n",
    "y = df_numeric[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x = df_numeric.drop(target, axis=1)\n",
    "features = x.columns.tolist()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](training_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn (importé en tant que sklearn) est la principale librairie permettant de faire du machine learning en python : https://scikit-learn.org/stable/user_guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_size_ratio = 0.2\n",
    "random_state = 123 \n",
    "# variable à utiliser pour pouvoir reproduir la même répartition sur plusiurs exécutions\n",
    "\n",
    "# TODO: trouver et utiliser la fonction de sklearn permettant de \n",
    "# \"splitter\" (séparer) des variables explicatives (x) et une cible (y)\n",
    "# en un jeu d'entraînement (x_train et y_train) et un jeu de test (x_test et y_test),\n",
    "# avec 80% de données d'entraînement et 20% de données de test\n",
    "x_train, x_test, y_train, y_test = ??\n",
    "assert(len(x_test) / (len(x_train) + len(x_test)) == test_size_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeRegressor(max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T16:52:03.230739Z",
     "start_time": "2020-10-02T16:52:03.226124Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: utiliser la méthode de l'objet tree_model permettant de le \"fitter\" (l'entraîner)\n",
    "# sur les données d'entraînement\n",
    "tree_model.??\n",
    "check_is_fitted(tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions sur l'ensemble d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: utiliser la méthode de l'objet tree_model entraîné \n",
    "# permettant de générer des prédictions sur les données d'entraînement \n",
    "predictions_train = tree_model.??\n",
    "assert(len(predictions_train) == len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème, c'est que la valeur d'erreur ci-dessus peut prendre des valeurs très différentes en fonction de la problématique. On préférera parfois utiliser des valeurs d'erreurs qui ont peuvent prendre des valeurs plus circonscrites, comme la fonction r2 utilisée ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](r2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "r2_score(predictions_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictions_vs_realite_train = pd.DataFrame({\"predictions sur ensemble d'entrainement\": predictions_train,\n",
    "                                           \"valeurs ensemble d'entrainement\": y_train})\n",
    "predictions_vs_realite_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_vs_realite_train.plot.scatter(x=\"predictions sur ensemble d'entrainement\", y=\"valeurs ensemble d'entrainement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: utiliser la méthode de l'objet tree_model entraîné \n",
    "# permettant de générer des prédictions sur les données de test \n",
    "predictions_test = tree_model.?? \n",
    "r2_score(predictions_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictions_vs_realite = pd.DataFrame({\"predictions sur ensemble de test\": predictions_test,\n",
    "                                       \"valeurs ensemble de test\": y_test})\n",
    "predictions_vs_realite.plot.scatter(x=\"predictions sur ensemble de test\", y=\"valeurs ensemble de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche des meilleurs paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![titile](training_and_test.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Création de l'ensemble de validation et d'un nouveau ensemble d'entraînement et \n",
    "# à partir de l'ancien ensemble d'entraînement\n",
    "x_training, x_val, y_training, y_val = train_test_split(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters_grid = {\"max_depth\": [None] + list(range(2, 12)), \n",
    "                        \"min_samples_split\": list(range(2, 20))}\n",
    "\n",
    "# Créons la liste de toutes les combinaisons possibles d'hyperparamètres\n",
    "hyperparameters_combinations_tuple_list = product(*(hyperparameters_grid[key] \n",
    "                                                    for key in hyperparameters_grid))\n",
    "hyperparameters_combinations_dict_list = [{\"max_depth\": l[0], \n",
    "                                           \"min_samples_split\": l[1]} for l in\n",
    "                                          hyperparameters_combinations_tuple_list]\n",
    "hyperparameters_combinations_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_score_with_a_decison_tree(hyperparameters):\n",
    "    tree = DecisionTreeRegressor(**hyperparameters)\n",
    "    # TODO: utiliser les méthodes vue précédemment\n",
    "    # pour entraîner le modèle tree sur le nouvel ensemble d'entraînement \n",
    "    # puis retourner son score R2 sur l'ensemble de validation\n",
    "    ??\n",
    "    predictions = ??\n",
    "    score = ??\n",
    "    return score\n",
    "\n",
    "assert(get_score_with_a_decison_tree({'max_depth': None, 'min_samples_split': 2}) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Pour chaque combinaison d'hyperparamètres, entraînons un arbre\n",
    "# et calculons son score sur l'ensemble de validation\n",
    "scores = [get_score_with_a_decison_tree(hyperparameter_combination) \n",
    "          for hyperparameter_combination in hyperparameters_combinations_dict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T17:03:25.654055Z",
     "start_time": "2020-10-02T17:03:25.554821Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_score = max(scores)\n",
    "print(\"Score du meilleur modèle sur l'ensemble où les hyperparamètres ont été optimisés: %s\" % max_score)\n",
    "best_score_index = scores.index(max_score)\n",
    "best_hyperparameters = hyperparameters_combinations_dict_list[best_score_index]\n",
    "best_tree = DecisionTreeRegressor(**best_hyperparameters).fit(x_train, y_train)\n",
    "print(\"Score du meilleur modèle sur l'ensemble de test: %s\" % best_tree.score(x_test, y_test))\n",
    "\n",
    "print(\"Meilleurs hyperparamètres: %s\" % best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictions_best_tree_vs_realite = pd.DataFrame({\"predictions sur ensemble de test\": best_tree.predict(x_test),\n",
    "                                                 \"valeurs ensemble de test\": y_test})\n",
    "predictions_best_tree_vs_realite.plot.scatter(x=\"predictions sur ensemble de test\", y=\"valeurs ensemble de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](kfolds.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_cross_val_score(hyperparameters):\n",
    "    scores = []\n",
    "    x_train_matrix = x_train.values\n",
    "    y_train_matrix = y_train.values\n",
    "    # Créons six sous-ensembles (folds) de taille égale\n",
    "    kfold = KFold(n_splits=6)\n",
    "    # Et récupérons tous les ensembles d'entraînement et de validation possibles\n",
    "    for train_indices, val_indices in kfold.split(x_train_matrix):\n",
    "        x_train_k = x_train_matrix[train_indices, :]\n",
    "        y_train_k = y_train_matrix[train_indices]\n",
    "        x_val_k = x_train_matrix[val_indices, :]\n",
    "        y_val_k = y_train_matrix[val_indices]\n",
    "        tree = DecisionTreeRegressor(**hyperparameters)\n",
    "        # TODO: entraîner le modèle sur le sous-ensemble d'entraînement,\n",
    "        # et récupérer son score sur le sous-ensemble de validation\n",
    "        score = ??\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "assert(get_cross_val_score({'max_depth': None, 'min_samples_split': 2}) <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "get_cross_val_score(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Recalculons les scores de chacune des combinaisons de paramètres\n",
    "cv_scores = [get_cross_val_score(hyperparameter_combination)\n",
    "             for hyperparameter_combination in hyperparameters_combinations_dict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "max_score_cv = max(cv_scores)\n",
    "print(\"Score du meilleur modèle sur l'ensemble de validation: %s\" % max_score_cv)\n",
    "best_score_index_cv = cv_scores.index(max_score_cv)\n",
    "best_hyperparameters_cv = hyperparameters_combinations_dict_list[best_score_index_cv]\n",
    "best_tree_cv = DecisionTreeRegressor(**best_hyperparameters_cv).fit(x_train, y_train)\n",
    "print(\"Score du meilleur modèle sur l'ensemble de test: %s\" % best_tree_cv.score(x_test, y_test))\n",
    "\n",
    "print(\"Meilleurs paramètres: %s\" % best_hyperparameters_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictions_vs_realite_cv = pd.DataFrame({\"predictions sur ensemble de test\": best_tree.predict(x_test),\n",
    "                                       \"valeurs ensemble de test\": y_test})\n",
    "predictions_best_tree_vs_realite.plot.scatter(x=\"predictions sur ensemble de test\", y=\"valeurs ensemble de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compromis biais variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bootstrap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "sample_size = 1000\n",
    "pool_size = x_train.shape[0]\n",
    "\n",
    "def get_bootstrap_sample(pool_size=pool_size, sample_size=sample_size):\n",
    "    return np.random.choice(range(pool_size), size=sample_size, replace=True)\n",
    "\n",
    "# Créons une liste d'indices d'échantillons \"bootstrap\" sur l'ensemble d'entraînement\n",
    "samples = [get_bootstrap_sample() for _ in range(n_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_individual_tree(sample, max_depth=2):\n",
    "    x_train_sample = x_train.values[sample, :]\n",
    "    y_train_sample = y_train.values[sample]\n",
    "    tree_sample = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    return tree_sample.fit(x_train_sample, y_train_sample)\n",
    "\n",
    "mean_bias, mean_variance = [], []\n",
    "scores_one_tree = []\n",
    "max_depths = range(1, 25, 4)\n",
    "# Pour différentes valeurs de profondeur possibles...\n",
    "for depth in max_depths:\n",
    "    # On va entraîner des arbres de décision, un par échantillon bootstrap\n",
    "    tree_samples = [train_individual_tree(sample, depth) for sample in samples]\n",
    "    # TODO: créeer une liste contenant les prédictions de chacun des arbres sur x_test\n",
    "    predictions_tree_samples = [?? for tree in tree_samples] \n",
    "    \n",
    "    # On calcule les taux d'erreur de chacun des arbres...\n",
    "    error_rates = np.concatenate([((x - y_test) / y_test).values.reshape(len(y_test), 1) \n",
    "                                for x in predictions_tree_samples],\n",
    "                              axis=1)\n",
    "    # Et on en déduit un taux d'erreur moyen, ou bias\n",
    "    mean_bias.append(np.mean(np.abs(np.mean(error_rates, axis=1))))\n",
    "    # et la variance des erreurs\n",
    "    mean_variance.append(np.mean(np.std(error_rates, axis=1)))\n",
    "    \n",
    "    one_tree = DecisionTreeRegressor(max_depth=depth).fit(x_train, y_train)\n",
    "    scores_one_tree.append(one_tree.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(max_depths, mean_bias)\n",
    "plt.title(u\"Évolution du biais en fonction de la profondeur des arbres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(max_depths, mean_variance)\n",
    "plt.title(u\"Évolution de la variance en fonction de la profondeur des arbres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(max_depths, scores_one_tree)\n",
    "plt.title(u\"Évolution du score d'un seul arbre en fonction de la profondeur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggrégation bootstrap (bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "score_bootstrap_aggregation_predictions = []\n",
    "# Pour chaque profondeur possible...\n",
    "for depth in max_depths:\n",
    "    # On va maintenant prédire la moyenne des prédictions des arbres\n",
    "    # entraînés sur les échantillons bootstrap\n",
    "    tree_samples = [train_individual_tree(sample, depth) for sample in samples]\n",
    "    predictions_tree_samples = [tree.predict(x_test) for tree in tree_samples]\n",
    "    bootstrap_aggregation_predictions = sum(predictions_tree_samples) / n_samples\n",
    "    score_bootstrap_aggregation_predictions.append(\n",
    "        r2_score(y_test, bootstrap_aggregation_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(max_depths, score_bootstrap_aggregation_predictions)\n",
    "plt.title(u\"Évolution de l'erreur de l'aggrégation bootstrap en fonction de la profondeur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualisons les prédictions pour des arbres de profondeur 10\n",
    "tree_samples = [train_individual_tree(sample, 10) for sample in samples]\n",
    "predictions_tree_samples = [tree.predict(x_test) for tree in tree_samples]\n",
    "bootstrap_aggregation_predictions = sum(predictions_tree_samples) / n_samples\n",
    "\n",
    "predictions_vs_realite_bootstrap_aggregation = pd.DataFrame({\"predictions sur ensemble de test\": bootstrap_aggregation_predictions,\n",
    "                                       \"valeurs ensemble de test\": y_test})\n",
    "predictions_vs_realite_bootstrap_aggregation.plot.scatter(x=\"predictions sur ensemble de test\", y=\"valeurs ensemble de test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forêt d'arbres aléatoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](random_forest.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=50, n_estimators=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](boosting_trees.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gbm = GradientBoostingRegressor(n_estimators=100, criterion=\"mse\")\n",
    "gbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gbm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: récupérer les données de départ, et remplacer les valeurs manquantes par la moyenne ou la médianne des valeurs de la colonne, en utilisant sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Remplacer les colonnes contenant des variables catégorielles par des colonnes contenant des 0 et des 1, indicant si l'échantillon appartient ou non à la catégorie, en utilisant sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
